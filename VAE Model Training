import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import os
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score
import datetime


# Define the enhanced VAE model for 256x256 images
class ComplexVAE(nn.Module):
    def __init__(self, latent_dim=512):
        super(ComplexVAE, self).__init__()
        self.latent_dim = latent_dim

        # Encoder
        self.enc_conv1 = nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1)
        self.enc_bn1 = nn.BatchNorm2d(32)
        self.enc_conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)
        self.enc_bn2 = nn.BatchNorm2d(64)
        self.enc_conv3 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)
        self.enc_bn3 = nn.BatchNorm2d(128)
        self.enc_conv4 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)
        self.enc_bn4 = nn.BatchNorm2d(256)
        self.enc_conv5 = nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1)
        self.enc_bn5 = nn.BatchNorm2d(512)
        self.enc_conv6 = nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1)

        self.fc1 = nn.Linear(1024 * 4 * 4, 512)
        self.fc_bn1 = nn.BatchNorm1d(512)
        self.fc2 = nn.Linear(512, latent_dim)
        self.fc3 = nn.Linear(512, latent_dim)

        # Decoder
        self.fc4 = nn.Linear(latent_dim, 512)
        self.fc_bn2 = nn.BatchNorm1d(512)
        self.fc5 = nn.Linear(512, 1024 * 4 * 4)

        self.dec_conv1 = nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1)
        self.dec_bn1 = nn.BatchNorm2d(512)
        self.dec_conv2 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)
        self.dec_bn2 = nn.BatchNorm2d(256)
        self.dec_conv3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)
        self.dec_bn3 = nn.BatchNorm2d(128)
        self.dec_conv4 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)
        self.dec_bn4 = nn.BatchNorm2d(64)
        self.dec_conv5 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)
        self.dec_bn5 = nn.BatchNorm2d(32)
        self.dec_conv6 = nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1)

    def encode(self, x):
        x = torch.nn.functional.leaky_relu(self.enc_bn1(self.enc_conv1(x)), negative_slope=0.2)
        x = torch.nn.functional.leaky_relu(self.enc_bn2(self.enc_conv2(x)), negative_slope=0.2)
        x = torch.nn.functional.leaky_relu(self.enc_bn3(self.enc_conv3(x)), negative_slope=0.2)
        x = torch.nn.functional.leaky_relu(self.enc_bn4(self.enc_conv4(x)), negative_slope=0.2)
        x = torch.nn.functional.leaky_relu(self.enc_bn5(self.enc_conv5(x)), negative_slope=0.2)
        x = torch.nn.functional.leaky_relu(self.enc_conv6(x))
        x = x.view(-1, 1024 * 4 * 4)
        x = torch.nn.functional.leaky_relu(self.fc_bn1(self.fc1(x)), negative_slope=0.2)
        mu = self.fc2(x)
        logvar = self.fc3(x)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z):
        z = torch.nn.functional.leaky_relu(self.fc_bn2(self.fc4(z)), negative_slope=0.2)
        z = torch.nn.functional.leaky_relu(self.fc5(z))
        z = z.view(-1, 1024, 4, 4)
        z = torch.nn.functional.leaky_relu(self.dec_bn1(self.dec_conv1(z)), negative_slope=0.2)
        z = torch.nn.functional.leaky_relu(self.dec_bn2(self.dec_conv2(z)), negative_slope=0.2)
        z = torch.nn.functional.leaky_relu(self.dec_bn3(self.dec_conv3(z)), negative_slope=0.2)
        z = torch.nn.functional.leaky_relu(self.dec_bn4(self.dec_conv4(z)), negative_slope=0.2)
        z = torch.nn.functional.leaky_relu(self.dec_bn5(self.dec_conv5(z)), negative_slope=0.2)
        z = torch.sigmoid(self.dec_conv6(z))
        return z

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar


# Define the enhanced loss function with balanced terms
def enhanced_loss_function(recon_x, x, mu, logvar, beta=1.0):
    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return BCE + beta * KLD


# Dataset class with RPM labels
class CustomDataset(Dataset):
    def __init__(self, image_dirs, rpms, transform=None):
        self.image_paths = []
        self.rpms = []
        self.transform = transform
        for dir_path, rpm in zip(image_dirs, rpms):
            for filename in os.listdir(dir_path):
                if filename.endswith(".png"):
                    self.image_paths.append(os.path.join(dir_path, filename))
                    self.rpms.append(rpm)

        print(f"Total images loaded: {len(self.image_paths)}")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        rpm = self.rpms[idx]
        return image, rpm


# Evaluation metrics 
def evaluate_model(model, dataloader, device):
    model.eval()
    mse_list = []

    with torch.no_grad():
        for images, _ in dataloader:
            images = images.to(device)
            recon_images, _, _ = model(images)
            recon_images = recon_images.cpu()

            for orig, recon in zip(images.cpu(), recon_images):
                orig_np = orig.permute(1, 2, 0).numpy()
                recon_np = recon.permute(1, 2, 0).numpy()

                # Ensure images are in 0-1 range
                orig_np = np.clip(orig_np, 0, 1)
                recon_np = np.clip(recon_np, 0, 1)

                # Calculate MSE
                  mse = np.mean((orig_np - recon_np) ** 2)
                mse_list.append(mse)

    avg_mse = np.mean(mse_list)

    return avg_mse, None  


# Plot latent space function 
def plot_latent_space(model, dataloader, device):
    # Placeholder function if needed in the future
    pass


# Save losses to file
def save_losses(epoch, train_loss, val_loss, filepath):
    with open(filepath, 'a') as f:
        f.write(f"Epoch {epoch}: Train Loss = {train_loss:.4f}, Validation Loss = {val_loss:.4f}\n")


ts = datetime.datetime.now()
print(f"Started at {ts}")

# Directories and corresponding RPMs
image_dirs = [
    '/Users/admin1/Documents/Audio/combined/NB25/mels_1',
    '/Users/admin1/Documents/Audio/combined/NB30/mels_1',
    '/Users/admin1/Documents/Audio/combined/NB40/mels_1',
    '/Users/admin1/Documents/Audio/combined/NB50/mels_1'
]

rpms = [899, 1438, 2277, 3296]

# Transformations for 256x256 images
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
])

# Dataset and DataLoader
dataset = CustomDataset(image_dirs, rpms, transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)

# Initialize the VAE model, loss function, and optimizer
latent_dim = 512
model = ComplexVAE(latent_dim=latent_dim)
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Training loop
num_epochs = 50
device = torch.device("cpu")
model.to(device)

loss_filepath = 'training_validation_losses_o5.txt'

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, _ in dataloader:
        images = images.to(device)
        optimizer.zero_grad()
        recon_images, mu, logvar = model(images)
        loss = enhanced_loss_function(recon_images, images, mu, logvar, beta=1.0)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_train_loss = running_loss / len(dataloader.dataset)

    # Evaluate on the validation set
    avg_val_mse, _ = evaluate_model(model, dataloader, device)  # Use the same dataloader for simplicity

    save_losses(epoch + 1, avg_train_loss, avg_val_mse, loss_filepath)

    ts = datetime.datetime.now()
    print(
        f"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Validation MSE: {avg_val_mse:.4f}, Time: {ts}")

# Save the trained model
model_path = 'o5_rpm_complex_vae_model.pth'
torch.save({
    'epoch': num_epochs,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': avg_train_loss,
}, model_path)
print(f"Model saved to {model_path}")
